{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgfrCWwt+G8D8Pmlx7PzdE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CallmeQuant/Studying-Notebook/blob/main/Miscellaneous/Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3InYriAhUy68"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **Basic Attention**"
      ],
      "metadata": {
        "id": "tMqX3m0fpDQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ Rather than using the final encoder hidden state, attention allows using information from **each encoder** step.\n",
        "+ The encoder outputs are weighted based on the decoder hidden state, concatenated into one context vector, put through the decoder to make prediction."
      ],
      "metadata": {
        "id": "7ZAzFFscU7TR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x, axis = 0):\n",
        "  \"\"\"\n",
        "  Compute the softmax for x along specified axis\n",
        "  axis=0 calculates softmax across rows which means each column sums to 1\n",
        "  axis=1 calculates softmax across columns which means each row sums to 1\n",
        "  \"\"\"\n",
        "  return np.exp(x) / np.expand_dims(np.sum(np.exp(x), axis = axis), axis)"
      ],
      "metadata": {
        "id": "1G1Rr8XkVgfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = [3.0, 1.0, 0.2]\n",
        "print(softmax(scores))\n",
        "\n",
        "scores2D = np.array([[1, 2, 3, 6],\n",
        "                     [2, 4, 5, 6],\n",
        "                     [3, 8, 7, 6]])\n",
        "\n",
        "print(softmax(scores2D))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE_eXq8YVrjM",
        "outputId": "b19a527f-5d3c-43bb-83ba-e0cbf55301e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8360188  0.11314284 0.05083836]\n",
            "[[0.09003057 0.00242826 0.01587624 0.33333333]\n",
            " [0.24472847 0.01794253 0.11731043 0.33333333]\n",
            " [0.66524096 0.97962921 0.86681333 0.33333333]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Computing Alignment Scores**\n",
        "\n",
        "+ A measure of similarity between decoder hidden state and each encoder hidden state. The operation is\n",
        "\n",
        "$$e_{ij} = v_{a}^{\\intercal} \\text{tanh}(W_{a} s_{i-1} + U_{a} h_{j})$$\n",
        "\n",
        "where $W_a \\in \\mathbb{R}^{n \\times m}$, $U_a \\in \\mathbb{R}^{n \\times m}$, and $v_{a} \\in \\in \\mathbb{R}^{m}$.\n",
        "\n",
        "+ Normally, this operation is implemented as a feedforward neural network with two layers, where m is the size of layers in the alignment network:\n",
        " + $h_{j}$ are encoder hidden states from each input step $j$ and last decoder hidden states are concatenated to produce array of size $K \\times 2n$ where $K$ is number of encoder states/steps.\n",
        "\n"
      ],
      "metadata": {
        "id": "b1h6ttyrYYkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 16\n",
        "attention_size = 10\n",
        "input_length = 5\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "encoder_states = np.random.randn(input_length, hidden_size)\n",
        "decoder_states = np.random.randn(1, hidden_size)\n",
        "\n",
        "# Weights for the neural network, these are typically learned through training\n",
        "# Use these in the alignment function below as the layer weights\n",
        "layer_1 = np.random.randn(2 * hidden_size, attention_size)\n",
        "layer_2 = np.random.randn(attention_size , 1)\n",
        "\n",
        "def alignment(encoder_states, decoder_state):\n",
        "  inputs = np.concatenate((encoder_states,\n",
        "                np.repeat(decoder_states, encoder_states.shape[0], axis = 0)),\n",
        "                axis = 1)\n",
        "  assert inputs.shape == (input_length, 2 * hidden_size)\n",
        "\n",
        "  activations = np.tanh(inputs @ layer_1)\n",
        "\n",
        "  assert activations.shape == (input_length, attention_size)\n",
        "\n",
        "  scores = activations @ layer_2\n",
        "\n",
        "  assert scores.shape == (input_length, 1)\n",
        "\n",
        "  return scores"
      ],
      "metadata": {
        "id": "aK7mrbChYXXA"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = alignment(encoder_states, decoder_states)\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfCkhe-wfrQv",
        "outputId": "ee3419d1-3025-4435-84f0-ab63558e0f12"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4.35790943]\n",
            " [5.92373433]\n",
            " [4.18673175]\n",
            " [2.11437202]\n",
            " [0.95767155]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Compute the Weights based on the Alignment Scores**\n",
        "\n",
        "+ These weights determine the encoder outputs that are the most important for the decoder output. These weights should be between 0 and 1, and add up to 1.\n",
        "+ Using softmax function tot return the weights of the attention score. Mathematically,\n",
        "\n",
        "$$\\alpha_{ij} = \\frac{\\exp(e_{ij})}{\\sum_{k = 1}^{K} \\exp(e_{ik})}$$\n",
        "\n",
        "where $K$ is number of encoder states.\n",
        "\n",
        "**Step 3: Weighting the Encoder Output vectors and Sum**\n",
        "\n",
        "+ The weights tell us the importance of each input word with respect to the decoder state.\n",
        "\n",
        "+ Multiply each encoder vector by its respective weight to get the alignment vectors\n",
        "+ Sum up the weighted alignment vectors to get the context vector.\n",
        "Mathematically,\n",
        "\n",
        "$$c_{i} = \\sum_{j = 1}^{K} \\alpha_{ij} h_{j}$$"
      ],
      "metadata": {
        "id": "qqJRcj-Zfy4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(encoder_states, decoder_state):\n",
        "    \"\"\"\n",
        "    Example function that calculates attention, returns the context vector\n",
        "    Parameters:\n",
        "      encoder_vectors: NxM numpy array, where N is the number of vectors and M is the vector length\n",
        "      decoder_vector: 1xM numpy array, M is the vector length, much be the same M as encoder_vectors\n",
        "    \"\"\"\n",
        "    scores = alignment(encoder_states, decoder_state)\n",
        "\n",
        "    weights = softmax(scores)\n",
        "\n",
        "    # Element-wise product\n",
        "    weighted_scores = weights * encoder_states\n",
        "\n",
        "    context = np.sum(weighted_scores, axis = 0)\n",
        "\n",
        "    # shorter\n",
        "    # context = np.dot(weighted_scores.T, encoder_states).flatten()\n",
        "\n",
        "    return context\n"
      ],
      "metadata": {
        "id": "VwQJTXoJfulH"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_vector = attention(encoder_states, decoder_states)\n",
        "print(context_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZRXk6XEkvy0",
        "outputId": "972dc7f2-71bd-448d-d797-d5539cf36078"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.63514569  0.04917298 -0.43930867 -0.9268003   1.01903919 -0.43181409\n",
            "  0.13365099 -0.84746874 -0.37572203  0.18279832 -0.90452701  0.17872958\n",
            " -0.58015282 -0.58294027 -0.75457577  1.32985756]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dot-Product Attention**"
      ],
      "metadata": {
        "id": "NYTBFBvPpGge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import scipy.special\n",
        "\n",
        "import textwrap\n",
        "wrapper = textwrap.TextWrapper(width=70)\n",
        "\n",
        "# to print the entire np array\n",
        "np.set_printoptions(threshold=sys.maxsize)"
      ],
      "metadata": {
        "id": "OawrpcRno9M0"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper functions to create tensor and display information"
      ],
      "metadata": {
        "id": "pnG5MYLKpS6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tensor(l):\n",
        "  return np.array(l)\n",
        "\n",
        "def display_tensor(t, name):\n",
        "  print(f'{name} shape: {t.shape}\\n')\n",
        "  print(f'{t}\\n')"
      ],
      "metadata": {
        "id": "FbbEtkUio98c"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create some tensors and display the shapes.\n",
        "\n",
        "The query, key, and value arrays must all have the same embedding dimensions (number of columns), and the mask array must have the same shape as `np.dot(query, key.T)`."
      ],
      "metadata": {
        "id": "0bzoIhG-p4Ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(128)\n",
        "q = create_tensor([[1, 0, 0], [0, 1, 0]])\n",
        "display_tensor(q, 'query')\n",
        "k = create_tensor([[1, 2, 3], [4, 5, 6]])\n",
        "display_tensor(k, 'key')\n",
        "v = create_tensor([[0, 1, 0], [1, 0, 1]])\n",
        "display_tensor(v, 'value')\n",
        "m = create_tensor([[0., -1e9],\n",
        "                   [0., 0.]]\n",
        "                  )\n",
        "display_tensor(m, 'mask')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9OD92FPpSmV",
        "outputId": "09e28560-4082-4b68-c30e-08f2809995c8"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query shape: (2, 3)\n",
            "\n",
            "[[1 0 0]\n",
            " [0 1 0]]\n",
            "\n",
            "key shape: (2, 3)\n",
            "\n",
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "\n",
            "value shape: (2, 3)\n",
            "\n",
            "[[0 1 0]\n",
            " [1 0 1]]\n",
            "\n",
            "mask shape: (2, 2)\n",
            "\n",
            "[[ 0.e+00 -1.e+09]\n",
            " [ 0.e+00  0.e+00]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compute dot product attention**\n",
        "\n",
        "$$\\text{softmax}\\Bigg(\\frac{QK^{\\intercal}}{\\sqrt{d}} + M\\Bigg)V$$"
      ],
      "metadata": {
        "id": "EY0U4fKSqdDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def DotProductAttention(query, key, value, mask, scale = True):\n",
        "  \"\"\"\n",
        "  Dot product self-attention.\n",
        "    Parameters:\n",
        "        query (numpy.ndarray): array of query representations with shape (L_q by d)\n",
        "        key (numpy.ndarray): array of key representations with shape (L_k by d)\n",
        "        value (numpy.ndarray): array of value representations with shape (L_k by d) where L_v = L_k\n",
        "        mask (numpy.ndarray): attention-mask, gates attention with shape (L_q by L_k)\n",
        "        scale (bool): whether to scale the dot product of the query and transposed key\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Self-attention array for q, k, v arrays. (L_q by d)\n",
        "  \"\"\"\n",
        "  assert query.shape[-1] == key.shape[-1] == value.shape[-1], \"Embedding dimensions of q, k, v aren't all the same\"\n",
        "\n",
        "  # Save depth/dimension of the query embedding for scaling down the dot product\n",
        "  if scale:\n",
        "      depth = query.shape[-1]\n",
        "  else:\n",
        "      depth = 1\n",
        "\n",
        "  # Compute the scaled query-key dot product\n",
        "\n",
        "  scaled_qk = (q @ k.T) / np.sqrt(depth) # np.matmul(query, np.swapaxes(key, -1, -2)) / np.sqrt(depth)\n",
        "\n",
        "  if mask is not None:\n",
        "    scaled_qk = np.where(mask, scaled_qk,  np.full_like(scaled_qk, -1e9))\n",
        "\n",
        "  # Using logsumexp trick to avoid underflow\n",
        "  logsumexp = scipy.special.logsumexp(scaled_qk, axis=-1, keepdims=True)\n",
        "\n",
        "  attention = scaled_qk @ value\n",
        "\n",
        "  return attention"
      ],
      "metadata": {
        "id": "X4OkPH92qamK"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(DotProductAttention(q, k, v, m))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RhKFh9E5OhA",
        "outputId": "ec256359-e27f-4b8c-ae97-4e1245577331"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2.30940108e+00 -1.00000000e+09  2.30940108e+00]\n",
            " [-1.00000000e+09 -1.00000000e+09 -1.00000000e+09]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dot_product_self_attention(q, k, v, scale=True):\n",
        "    \"\"\"\n",
        "    Masked dot product self attention.\n",
        "    Parameters:\n",
        "        q (numpy.ndarray): queries.\n",
        "        k (numpy.ndarray): keys.\n",
        "        v (numpy.ndarray): values.\n",
        "    Returns:\n",
        "        numpy.ndarray: masked dot product self attention tensor.\n",
        "    \"\"\"\n",
        "    # Size of the penultimate dimension of the query\n",
        "    mask_size = q.shape[-2]\n",
        "\n",
        "    # Creates a matrix with ones below the diagonal and 0s above with shape (1, mask_size, mask_size)\n",
        "    # Use np.tril() - Lower triangle of an array and np.ones()\n",
        "    mask = np.tril(np.ones((1, mask_size, mask_size), dtype = np.bool_), k = 0)\n",
        "\n",
        "    return DotProductAttention(q, k, v, mask, scale = True)"
      ],
      "metadata": {
        "id": "escS_OJ9CLUY"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dot_product_self_attention(q, k, v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCbaK0B1Djpi",
        "outputId": "9481566a-d9ff-472d-8c9d-99ef5211d8f4"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-1.00000000e+09,  5.77350269e-01, -1.00000000e+09],\n",
              "        [ 2.88675135e+00,  1.15470054e+00,  2.88675135e+00]]])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    }
  ]
}